import re
import scrapy
from goto_eat_scrapy.items import ShopItem
from goto_eat_scrapy.spiders.abstract import AbstractSpider

class TottoriSpider(AbstractSpider):
    """
    usage:
      $ scrapy crawl tottori -O tottori.csv
    """
    name = 'tottori'
    allowed_domains = [ 'tottori-gotoeat.jp' ]
    start_urls = ['https://tottori-gotoeat.jp/store_list/']

    def parse(self, response):
        # å„åŠ ç›Ÿåº—æƒ…å ±ã‚’æŠ½å‡º
        self.logzero_logger.info(f'ğŸ’¾ url = {response.request.url}')
        for article in response.xpath('//div[@class="row"]//div[contains(@class, "store-list_v2")]'):
            item = ShopItem()
            item['shop_name'] = article.xpath('.//div[1]/h2[contains(@class, "mr-3")]/text()').get().strip()

            # MEMO: (2020/11/22) ç†ç”±ã¯ã‚ã‹ã‚‰ãªã„ãŒã€å…¬å¼ã‚µã‚¤ãƒˆã§ã‚‚æ¤œç´¢ã™ã‚‹ã¨ãƒšãƒ¼ã‚¸ã«ã¾ãŸãŒã£ã¦åŒã˜ãƒ‡ãƒ¼ã‚¿ãŒå‡ºã¦ãã‚‹ã‚‚ã®ãŒã‚ã‚‹
            # ä¾‹: ãã°å‡¦äº•ç”°è¾²åœ’(P.5ã€œP.7)
            # ä¾‹: ãƒŸãƒ‹ãƒ¬ã‚¹ãƒˆã‚­ãƒ¥ãƒ¼ãƒ”ãƒƒãƒˆ(P.6ã€œP.7)
            # ã“ã‚Œã‚‰ãŒé‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆã•ã‚Œã¦ã—ã¾ã†ãŒã€å…¬å¼ã‚µã‚¤ãƒˆå´ã§ã‚‚ãã†è¡¨ç¤ºã•ã‚Œã¦ã—ã¾ã†ã®ã§(ç†ç”±ã¯è¬â€¦) å¯¾å‡¦æ–¹æ³•ãŒãªã„ã€‚
            # åº—åã ã‘ã§æ¤œç´¢ã—ã¦ã‚‚é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã¯å‡ºã¦ã“ãªã„ã®ã§ã€limit offsetã§ãƒšãƒ¼ã‚¸åˆ†ã‘ã—ãŸã¨ãã«order byã§æŒ‡å®šã—ãŸã‚½ãƒ¼ãƒˆãŒãƒ¦ãƒ‹ãƒ¼ã‚¯ã«åŠ¹ã„ã¦ãªãã¦
            # (created_at, updated_atã§ã‚½ãƒ¼ãƒˆã‹ã‘ã¦ã‚‹ã¨ã‹ã§)åŒé †ãƒ‡ãƒ¼ã‚¿ãŒå¤šæ•°ã‚ã‚‹å ´åˆã«ã«ãƒšãƒ¼ã‚¸ãŒåˆ†ã‹ã‚Œã¦ã—ã¾ã†ã¨ã‹ãªã‚“ã˜ã‚ƒãªã„ã‹ã¨æ€ã†
            # 2020/11/28æ²»ã£ã¦ã‚‹ã‹ã‚‚ï¼Ÿ

            # MEMO: ä»¥ä¸‹ã¯ä»Šå¾Œå…¥ã‚Œã¦ã‚‚ã‚ˆã„ã‹ã‚‚ã€ã¨ã„ã†é …ç›®
            # area: article.xpath('.//div[1]/p[1]/span[@class="icon-area"]/text()').get().strip()
            # comment: article.xpath('.//div[1]/p[2]/text()').get()

            item['address'] = article.xpath('.//div[2]/p/text()').get().strip()
            item['tel'] = article.xpath('.//div[2]/div[@class="d-flex"]/a/@href').get()

            genres = article.xpath('.//p[@class="mb-0"]/span[contains(@class, "icon-genre")]/text()').getall()
            item['genre_name'] = '|'.join(genres)

            self.logzero_logger.debug(item)
            yield item

        # ã€Œ>ã€ãƒœã‚¿ãƒ³ãŒãªã‘ã‚Œã°(æœ€çµ‚ãƒšãƒ¼ã‚¸ãªã®ã§)çµ‚äº†
        next_page = response.xpath('//nav[@role="navigation"]/div[@class="nav-links"]/a[@class="next page-numbers"]/@href').extract_first()
        if next_page is None:
            self.logzero_logger.info('ğŸ’» finished. last page = ' + response.request.url)
            return

        self.logzero_logger.info(f'ğŸ›« next url = {next_page}')

        yield scrapy.Request(next_page, callback=self.parse)
