import re
import scrapy
from goto_eat_scrapy.items import ShopItem
from goto_eat_scrapy.spiders.abstract import AbstractSpider

class TottoriSpider(AbstractSpider):
    """
    usage:
      $ scrapy crawl tottori -O tottori.csv
    """
    name = 'tottori'
    allowed_domains = [ 'tottori-gotoeat.jp' ]
    start_urls = ['https://tottori-gotoeat.jp/store_list/']

    def parse(self, response):
        # å„åŠ ç›Ÿåº—æƒ…å ±ã‚’æŠ½å‡º
        self.logzero_logger.info(f'ğŸ’¾ url = {response.request.url}')
        for article in response.xpath('//div[@class="row"]//div[contains(@class, "store-list_v2")]'):
            item = ShopItem()
            item['area_name'] = article.xpath('.//div[1]/p[1]/span[@class="icon-area"]/text()').get().strip()
            item['shop_name'] = article.xpath('.//div[1]/h2[contains(@class, "mr-3")]/text()').get().strip()

            # MEMO: (2020/11/22) ç†ç”±ã¯ã‚ã‹ã‚‰ãªã„ãŒã€å…¬å¼ã‚µã‚¤ãƒˆã§ã‚‚æ¤œç´¢ã™ã‚‹ã¨ãƒšãƒ¼ã‚¸ã«ã¾ãŸãŒã£ã¦åŒã˜ãƒ‡ãƒ¼ã‚¿ãŒå‡ºã¦ãã‚‹ã‚‚ã®ãŒã‚ã‚‹
            # ã“ã‚Œã‚‰ãŒé‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆã•ã‚Œã¦ã—ã¾ã†ãŒã€å…¬å¼ã‚µã‚¤ãƒˆå´ã§ã‚‚ãã®ã‚ˆã†ã«è¡¨ç¤ºã•ã‚Œã¦ã—ã¾ã£ã¦ã„ã‚‹ã®ã§å¯¾å‡¦æ–¹æ³•ãŒãªã„ã€‚
            # åº—åã ã‘ã§æ¤œç´¢ã—ã¦ã‚‚é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã¯å‡ºã¦ã“ãªã„ã®ã§ã€RDBMSå´ã§limit offsetã§ãƒšãƒ¼ã‚¸åˆ†ã‘ã—ãŸã¨ãã«order byã§æŒ‡å®šã—ãŸã‚½ãƒ¼ãƒˆé †ã®çµæœãŒ
            # ãƒ¦ãƒ‹ãƒ¼ã‚¯ã«ãªã£ã¦ãŠã‚‰ãš(created_at, updated_atã§ã‚½ãƒ¼ãƒˆã‹ã‘ã¦ã‚‹ã¨ã‹ã§)åŒé †ãƒ‡ãƒ¼ã‚¿ãŒå¤šæ•°ã‚ã‚‹å ´åˆã«ãƒšãƒ¼ã‚¸ãŒåˆ†ã‹ã‚Œã¦ã—ã¾ã†ã¨ã€
            # çµæœã¨ã—ã¦çµæœãŒä¸€æ„ã«ãªã‚‰ãªã„ã€ã¨ã‹ãªã‚“ã˜ã‚ƒãªã„ã‹ã¨æ€ã†ã€‚å†…éƒ¨çš„ã«ã¯WPã£ã½ã„ã‘ã©ã“ã‚Œä»¥ä¸Šã¯ãªã‚“ã¨ã‚‚â€¦

            # MEMO: åº—ã‹ã‚‰ã®ä¸€è¨€ã‚³ãƒ¡ãƒ³ãƒˆã€å¦™ã«å¥½ãâ€¦
            # comment = article.xpath('.//div[1]/p[2]/text()').get()
            # ä»–ã«ã‚‚ãƒ†ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã®æœ‰ç„¡ãªã©ã€é³¥å–ã¯æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒè±ªè¯

            item['address'] = article.xpath('.//div[2]/p/text()').get().strip()
            item['tel'] = article.xpath('.//div[2]/div[@class="d-flex"]/a/@href').get()

            genres = article.xpath('.//p[@class="mb-0"]/span[contains(@class, "icon-genre")]/text()').getall()
            item['genre_name'] = '|'.join(genres)

            self.logzero_logger.debug(item)
            yield item

        # ã€Œ>ã€ãƒœã‚¿ãƒ³ãŒãªã‘ã‚Œã°(æœ€çµ‚ãƒšãƒ¼ã‚¸ãªã®ã§)çµ‚äº†
        next_page = response.xpath('//nav[@role="navigation"]/div[@class="nav-links"]/a[@class="next page-numbers"]/@href').extract_first()
        if next_page is None:
            self.logzero_logger.info('ğŸ’» finished. last page = ' + response.request.url)
            return

        self.logzero_logger.info(f'ğŸ›« next url = {next_page}')

        yield scrapy.Request(next_page, callback=self.parse)
