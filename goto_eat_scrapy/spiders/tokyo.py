import re
import scrapy
import w3lib
import json
from logzero import logger
from goto_eat_scrapy.items import ShopItem

class TokyoSpider(scrapy.Spider):
    """
    usage:
      $ scrapy crawl tokyo -O 13_tokyo.csv
    """
    name = 'tokyo'
    allowed_domains = [ 'r.gnavi.co.jp' ]

    # ä¼æ¥­ã‚µã‚¤ãƒˆãªã®ã§(ãã‚Œã‚‚ã©ã†ã‹ã¨æ€ã†ãŒâ€¦) ä¸€å¿œæ°—ã‚’ä½¿ã†
    custom_settings = {
        'CONCURRENT_REQUESTS': 1,
        'CONCURRENT_REQUESTS_PER_DOMAIN': 1,
        'CONCURRENT_REQUESTS_PER_IP': 0,
        'DOWNLOAD_DELAY': 3,
        # 'LOG_LEVEL': 'INFO',
    }

    start_urls = [
        # ç´™ã¨ãƒ‡ã‚¸ã‚¿ãƒ«ä¸¡æ–¹ä½¿ãˆã‚‹æ–¹ã ã‘ã¨ã—ãŸ
        # 'https://r.gnavi.co.jp/area/tokyo/kods17214/rs/?sc_lid=gtetokyo_top_search_analog', # éƒ½å†…å…¨ä½“
        # 'https://r.gnavi.co.jp/area/areal2228/kods17214/rs/?resp=1&fwp=%E9%8C%A6%E7%B3%B8%E7%94%BA%E3%83%BB%E6%8A%BC%E4%B8%8A%E3%83%BB%E6%96%B0%E5%B0%8F%E5%B2%A9', # éŒ¦ç³¸ç”º
        'https://r.gnavi.co.jp/area/areal2273/kods17214/rs/?gtet_all=1&resp=1&fwp=%E5%BA%9C%E4%B8%AD%E3%83%BB%E8%AA%BF%E5%B8%83', # èª¿å¸ƒ
    ]

    def parse(self, response):
        # å„åŠ ç›Ÿåº—æƒ…å ±ã‚’æŠ½å‡º
        for article in response.xpath('//div[@class="result-cassette__wrapper result-cassette__wrapper--normal"]/ul[@class="result-cassette__list"]/li'):
            url = article.xpath('.//div[@class="result-cassette__box"]//a[@class="result-cassette__box-title js-measure"]/@href').get()
            yield scrapy.Request(url, callback=self.detail)

        # ã€Œ>ã€ãƒœã‚¿ãƒ³ãŒãªã‘ã‚Œã°(æœ€çµ‚ãƒšãƒ¼ã‚¸ãªã®ã§)çµ‚äº†
        next_page = response.xpath('//nav//li[@class="pagination__arrow-item"]/a[@class="pagination__arrow-item-inner pagination__arrow-item-inner-next"]/@href').extract_first()
        if next_page is None:
            logger.info('ğŸ’» finished. last page = ' + response.request.url)
            return

        logger.info(f'ğŸ›« next url = {next_page}')

        yield scrapy.Request(next_page, callback=self.parse)

    def detail(self, response):
        item = ShopItem()
        logger.debug(response.url) # TODO: æ±äº¬ã«é™ã‚‰ãšã€csvã«detailã®urlã€å…¥ã‚Œã¦ã‚„ã‚‹ã»ã†ãŒã„ã„ã‹ã‚‚ã—ã‚Œãªã„
        for tr in response.xpath('//div[@id="info-table"]/table/tbody'):
            item['shop_name'] = tr.xpath('.//tr/th[contains(text(), "åº—å")]/following-sibling::td/p[@id="info-name"]/text()').get().strip()
            item['tel'] = tr.xpath('.//tr/th[contains(text(), "é›»è©±ç•ªå·ãƒ»FAX")]/following-sibling::td/ul/li/span[@class="number"]/text()').get()

            # data-oã«å…¥ã£ã¦ã‚‹è¬jsonï¼Ÿã‚’parse
            data_o = tr.xpath('.//tr/th[contains(text(), "ãŠåº—ã®ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸")]/following-sibling::td/ul/li/a[@class="url go-off"]/@data-o').get()
            if data_o:
                data = json.loads(data_o)
                item['offical_page'] = data['b'] + '://' + data['a']

            zip_code = tr.xpath('.//tr/th[contains(text(), "ä½æ‰€")]/following-sibling::td/p[@class="adr slink"]/text()').get()
            item['zip_code'] = zip_code.strip().replace('ã€’', '') if zip_code else None
            item['address'] = tr.xpath('.//tr/th[contains(text(), "ä½æ‰€")]/following-sibling::td/p[@class="adr slink"]/span[@class="region"]/text()').get().strip()

            text = tr.xpath('.//tr/th[contains(text(), "å–¶æ¥­æ™‚é–“")]/following-sibling::td/div/text()').get()
            item['opening_hours'] = w3lib.html.remove_tags(text).strip() if text else None

            texts = tr.xpath('.//tr/th[contains(text(), "å®šä¼‘æ—¥")]/following-sibling::td/ul/li/text()').getall()
            item['closing_day'] = '\n'.join(texts)

        ## ã‚¸ãƒ£ãƒ³ãƒ«ç®—å‡º
        # "header-meta-gen-desc"ãŒã‚ã‚Œã°ãã¡ã‚‰ã‚’ã‚¸ãƒ£ãƒ³ãƒ«ã¨ã—ã¦åˆ©ç”¨(è¤‡æ•°ã‚¸ãƒ£ãƒ³ãƒ«ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹)
        genre_list = []
        for genre in response.xpath('//header[@role="banner"]//dd[@id="header-meta-gen-desc"]/ol/li'):
            genre_list.append(genre.xpath('.//a/text()').get().strip())
        if genre_list:
            item['genre_name'] = '|'.join(genre_list)
        else:
            # "header-meta-gen-desc"ãŒãªã„å ´åˆã¯ä»¥ä¸‹ã‚’åˆ©ç”¨(å˜ä¸€)
            # TODO: ã“ã¡ã‚‰ã‚’åˆ©ç”¨ã™ã‚‹å ´åˆã€ã‚¸ãƒ£ãƒ³ãƒ«åˆ†ã‘ãŒã¾ã£ãŸãæ•´ç†ã•ã‚Œã¦ãªã„ã®ã§(é¬¼ç•œ)ã€€csv2geojsonã®æ–¹ã§ãã¡ã‚“ã¨ã‚¸ãƒ£ãƒ³ãƒ«ã®åå¯„ã›ã‚’ã‚„ã‚‹ã“ã¨
            item['genre_name'] = response.xpath('//header[@role="banner"]//dd[@id="header-meta-cat-desc"]/text()').get().strip()


        return item

