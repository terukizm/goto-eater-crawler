import re
import scrapy
from goto_eat_scrapy.items import ShopItem
from goto_eat_scrapy.spiders.abstract import AbstractSpider

class GunmaSpider(AbstractSpider):
    """
    usage:
      $ scrapy crawl gunma -O gunma.csv
    """
    name = 'gunma'
    allowed_domains = [ 'gunma-gotoeat-campaign.com' ] # .comã¨ã¯

    # ã‚µã‚¤ãƒˆä¸Šã¯å…¥åŠ›åˆ¶é™ã§åŒæ™‚ã«3ã¤ã¾ã§ã—ã‹ã‚¸ãƒ£ãƒ³ãƒ«æŒ‡å®šãŒã§ããªã„ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ãŸã‚ã€ãŠä½œæ³•ã«å¾“ã†ãªã‚‰åˆ¶é™ã•ã›ãŸä¸Šã§
    # ã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã•ã›ã‚Œã°ã‚ˆã„ã®ã ãŒã€å†…éƒ¨å®Ÿè£…çš„ã«ãã‚Œã§ã‚·ã‚¹ãƒ†ãƒ è² è·ãŒæ¸›ã‚‹ã‚ã‘ã§ã‚‚ãªã•ãã†ãªã®ã§ã€è¡Œå„€ãŒæ‚ªã„ãŒ
    # ã‚¯ã‚¨ãƒªã‚’ã„ã˜ã£ã¦ã‚¸ãƒ£ãƒ³ãƒ«æŒ‡å®šãªã—ã§æ¤œç´¢ã—ã¦ã„ã‚‹ã€‚
    # (ã‚ã¨åˆè¨ˆä»¶æ•°ãŒåˆã‚ãªã„ã®ã§ãŠãã‚‰ãã‚«ãƒ†ã‚´ãƒªãªã—ã«ãªã£ã¦ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒ1ä»¶ã‚ã‚Š(å¾Œè¿°)ã€ãã‚Œã®ç¢ºèªã‚‚å…¼ã­ã¦ã„ã‚‹)
    start_urls = ['https://gunma-gotoeat-campaign.com/shop/?s=&post_type=shop']

    def parse(self, response):
        # å„åŠ ç›Ÿåº—æƒ…å ±ã‚’æŠ½å‡º
        self.logzero_logger.info(f'ğŸ’¾ url = {response.request.url}')
        for article in response.xpath('//section[@id="result"]/article'):
            item = ShopItem()

            genre = article.xpath('.//div[2]/span[@class="shopcat"]/text()').get() # æœ¬æ¥ã¯MUST
            if not genre:
                # MEMO: 2020/11/27ç¾åœ¨ã€ã€ŒèˆŸæœ¨äº­é¤¨æ—åº—ã€ã ã‘ã‚¸ãƒ£ãƒ³ãƒ«è¨­å®šãŒãªã„(å…¥åŠ›ãƒŸã‚¹ï¼Ÿ)
                self.logzero_logger.warn('â›” no genre name.')
            item['genre_name'] = genre.strip() if genre else None
            item['area_name'] = article.xpath('.//div[1]/span/text()').get().strip()

            item['shop_name'] = article.xpath('.//div[2]/h3/text()').get().strip()
            item['zip_code'] =  article.xpath('.//div[2]/p[@class="shopadr"]/span/text()').get()[1:]
            item['address'] =  article.xpath('.//div[2]/p[@class="shopadr"]/text()').get().strip()

            # ã‚ªãƒ—ã‚·ãƒ§ãƒ³é …ç›®
            tel = article.xpath('.//div[2]/p[@class="shoptel"]/text()').get()
            item['tel'] = tel.replace('TEL.', '') if tel else None
            item['offical_page'] = article.xpath('.//div[2]/div[@class="shopinfo"]/a[2]/@href').get()

            self.logzero_logger.debug(item)
            yield item

        # ã€Œ>ã€ãƒœã‚¿ãƒ³ãŒãªã‘ã‚Œã°(æœ€çµ‚ãƒšãƒ¼ã‚¸ãªã®ã§)çµ‚äº†
        next_page = response.xpath('//*[@id="search_page_outer"]//a[@class="next page-numbers"]/@href').extract_first()
        if next_page is None:
            self.logzero_logger.info('ğŸ’» finished. last page = ' + response.request.url)
            return

        self.logzero_logger.info(f'ğŸ›« next url = {next_page}')

        yield scrapy.Request(next_page, callback=self.parse)
