import re
import scrapy
from logzero import logger
from goto_eat_scrapy.items import ShopItem

class GunmaSpider(scrapy.Spider):
    """
    usage:
      $ scrapy crawl gunma -O output.csv
    """
    name = 'gunma'
    allowed_domains = [ 'gunma-gotoeat-campaign.com' ]

    # HPä¸Šã¯å…¥åŠ›åˆ¶é™ã§åŒæ™‚ã«3ã¤ã¾ã§ã—ã‹ã‚¸ãƒ£ãƒ³ãƒ«æŒ‡å®šãŒã§ããªã„ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã€‚ãŠä½œæ³•ã«å¾“ã†ãªã‚‰åŒæ§˜ã«åˆ¶é™ã•ã›ãŸä¸Šã§
    # ã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã•ã›ã‚Œã°ã‚ˆã„ã®ã ãŒã€å†…éƒ¨å®Ÿè£…çš„ã«ãã‚Œã§ã‚·ã‚¹ãƒ†ãƒ è² è·ãŒæ¸›ã‚‹ã‚ã‘ã§ã‚‚ãªã•ãã†ãªã®ã§ã€è¡Œå„€ãŒæ‚ªã„ãŒ
    # ã‚¯ã‚¨ãƒªã„ã˜ã£ã¦ã‚¸ãƒ£ãƒ³ãƒ«æŒ‡å®šãªã—ã§æ¤œç´¢ã—ã¦ã„ã‚‹ã€‚
    # (ã‚ã¨åˆè¨ˆä»¶æ•°ãŒåˆã‚ãªã„ã®ã§ãŠãã‚‰ãã‚«ãƒ†ã‚´ãƒªãªã—ã«ãªã£ã¦ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒ1ä»¶ã‚ã‚‹ã€‚ã¡ã‚‡ã£ã¨æ°—ã«ãªã‚‹ã®ã§ãã‚Œã®ç¢ºèªã‚‚å…¼ã­ã¦ã€‚)
    start_urls = ['https://gunma-gotoeat-campaign.com/shop/?s=&post_type=shop']

    def parse(self, response):
        # å„åŠ ç›Ÿåº—æƒ…å ±ã‚’æŠ½å‡º
        for article in response.xpath('//section[@id="result"]/article'):
            item = ShopItem()
            item['genre_name'] = article.xpath('.//div[2]/span[@class="shopcat"]/text()').get() # ã€ŒèˆŸæœ¨äº­é¤¨æ—åº—ã€ã ã‘ã‚¸ãƒ£ãƒ³ãƒ«ãŒãªã„
            item['shop_name'] = article.xpath('.//div[2]/h3/text()').get().strip()
            item['zip_code'] =  article.xpath('.//div[2]/p[@class="shopadr"]/span/text()').get()[1:]
            item['address'] =  article.xpath('.//div[2]/p[@class="shopadr"]/text()').get().strip()

            # ã‚ªãƒ—ã‚·ãƒ§ãƒ³é …ç›®
            tel = article.xpath('.//div[2]/p[@class="shoptel"]/text()').get()
            item['tel'] = tel.replace('TEL.', '') if tel else None
            item['offical_page'] = article.xpath('.//div[2]/div[@class="shopinfo"]/a[2]/@href').get()

            yield item

        # ã€Œ>ã€ãƒœã‚¿ãƒ³ãŒãªã‘ã‚Œã°(æœ€çµ‚ãƒšãƒ¼ã‚¸ãªã®ã§)çµ‚äº†
        next_page = response.xpath('//*[@id="search_page_outer"]//a[@class="next page-numbers"]/@href').extract_first()
        if next_page is None:
            logger.info('ğŸ’» finished. last page = ' + response.request.url)
            return

        logger.info(f'ğŸ›« next url = {next_page}')

        yield scrapy.Request(next_page, callback=self.parse)
