import json
import pathlib

import numpy as np
import scrapy

from goto_eat_scrapy.items import ShopItem
from goto_eat_scrapy.spiders.abstract import AbstractSpider


def _get_max_and_min(coordinates: list):
    """
    GeoJSONã®features.geometry.coordinatesã‹ã‚‰ã€1kmãƒ¡ãƒƒã‚·ãƒ¥ã«å«ã¾ã‚Œã‚‹latlngã®min/maxã‚’æ±‚ã‚ã‚‹
    (ã“ã‚ŒãŒx1,x2,y1,y2ã®å„å€¤ã¨å¯¾å¿œ)
    """
    for i, coords in enumerate(coordinates[0]):
        lat = coords[1]
        lng = coords[0]
        if i == 0:
            lat_min = lat
            lat_max = lat
            lng_min = lng
            lng_max = lng
            continue
        if lat < lat_min:
            lat_min = lat
        if lat_max < lat:
            lat_max = lat
        if lng < lng_min:
            lng_min = lng
        if lng_max < lng:
            lng_max = lng

    return (lat_min, lat_max, lng_min, lng_max)


class AbstractLinySpider(AbstractSpider):
    allowed_domains = ["liny.jp"]

    def start_requests(self):
        path = pathlib.Path(__file__).parent / "1km_mesh" / self.mesh_geojson_name
        with open(path) as f:
            geojson = json.load(f)
            for record in geojson["features"]:
                x1, x2, y1, y2 = _get_max_and_min(record["geometry"]["coordinates"])
                url = f"{self.base_url}?x1={x1}&x2={x2}&y1={y1}&y2={y2}"
                self.logzero_logger.info(f"ğŸ’¾ url = {url}")
                yield scrapy.Request(url, callback=self.parse)

    def parse(self, response):
        # jsonå½¢å¼ãªã®ã§ã€response.body(bytes)ã‚’ç›´æ¥èª­ã‚ã‚‹
        for article in json.loads(response.body)["data"]:
            item = ShopItem(
                shop_name=article["name"],
                address=article["address"],
                tel=article["tel"],
                official_page=article["url"],
                # MEMO: eigyo_jikanå†…ã«å®šä¼‘æ—¥ã‚‚å«ã¾ã‚Œã¦ã„ã‚‹ãŒåŸºæœ¬çš„ã«è‡ªç”±æ›¸å¼ã®ãŸã‚ã€åˆ†åˆ¥ã—ã‚ˆã†ãŒãªã„
                # ã¾ã¨ã‚ã¦å…¨éƒ¨ã€å–¶æ¥­æ™‚é–“ã®æ–¹ã«å…¥ã‚Œã¦ãŠã
                opening_hours=article["eigyo_jikan"],
                # MEMO: linyç³»ã¯å…¬å¼ã«latlng(google mapã®çµæœã¨ã¯ã¾ãŸåˆ¥ã£ã½ã„â€¦ï¼Ÿ)ãŒæä¾›ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€
                # ã“ã‚Œã‚’ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã›ãšã«ãã®ã¾ã¾ä½¿ãˆã°ç²¾åº¦ãŒå‡ºã›ã‚‹
                provided_lat=article["latlng"]["lat"],
                provided_lng=article["latlng"]["lng"],
            )

            yield item


if __name__ == "__main__":
    # usage:
    # $ python -m goto_eat_scrapy.spiders.abstract_liny
    coordinates = [
        [
            [140.1125, 35.5416666666667],
            [140.125, 35.5416666666667],
            [140.125, 35.55],
            [140.1125, 35.55],
            [140.1125, 35.5416666666667],
        ]
    ]
    x1, x2, y1, y2 = _get_max_and_min(coordinates)
    assert x1 == 35.5416666666667
    assert x2 == 35.55
    assert y1 == 140.1125
    assert y2 == 140.125

    print("success!!")
