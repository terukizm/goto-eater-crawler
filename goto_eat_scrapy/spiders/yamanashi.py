import re
import scrapy
from goto_eat_scrapy.items import ShopItem
from goto_eat_scrapy.spiders.abstract import AbstractSpider

class YamanashiSpider(AbstractSpider):
    """
    usage:
      $ scrapy crawl yamanashi -O output.csv
    """
    name = 'yamanashi'
    allowed_domains = [ 'gotoeat-yamanashi.jp' ]

    # å±±æ¢¨çœŒã¯ã“ã®1ãƒšãƒ¼ã‚¸ã ã‘ã§OK(ãƒšãƒ¼ã‚¸ãƒ³ã‚°ãªã—)
    start_urls = ['https://www.gotoeat-yamanashi.jp/archives/merchant']

    def parse(self, response):
        # å¸‚åŒºç”ºæ‘å˜ä½(ç”²åºœå¸‚ã€œå°è…æ‘)
        self.logzero_logger.info(f'ğŸ’¾ url = {response.request.url}')
        for section in response.xpath('//*[@id="shopList"]/section[@class="shopInfoSection"]'):
            area_name = section.xpath('.//h1/text()').get().strip()
            # ãƒ†ãƒ¼ãƒ–ãƒ«ä¸­ã®å„è¡Œã‚’parse(å…ˆé ­è¡Œã¯ãƒ˜ãƒƒãƒ€ãªã®ã§é£›ã°ã™)
            for tr in section.xpath('.//div[@class="secInnr"]/table[@class="shopTable"]/tr')[1:]:
                item = ShopItem(
                    area_name = area_name,
                    shop_name = tr.xpath('.//td[1]/text()').get().strip(),
                    genre_name = tr.xpath('.//td[1]/span[@class="genre"]/a/text()').get().strip(),
                    address = tr.xpath('.//td[2]/text()').get().strip(),
                    tel = tr.xpath('.//td[3]/text()').get().strip(),
                )
                self.logzero_logger.debug(item)
                yield item
