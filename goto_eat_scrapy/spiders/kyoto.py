import re
import scrapy
from goto_eat_scrapy.items import ShopItem
from goto_eat_scrapy.spiders.abstract import AbstractSpider

class KyotoSpider(AbstractSpider):
    """
    usage:
      $ scrapy crawl kyoto -O output.csv
    """
    name = 'kyoto'
    allowed_domains = [ 'kyoto-gotoeat.com' ]   # .comã¨ã¯
    start_urls = ['https://kyoto-gotoeat.com/?s=#keyword']

    def parse(self, response):
        # å„åŠ ç›Ÿåº—æƒ…å ±ã‚’æŠ½å‡º
        self.logzero_logger.info(f'ğŸ’¾ url = {response.request.url}')
        for article in response.xpath('//main[@id="main"]//div[@class="store-item"]'):
            item = ShopItem()
            item['shop_name'] = article.xpath('.//div[@class="name"]/a/text()').get().strip()
            item['genre_name'] = article.xpath('.//table/tr/th[contains(text(), "ã‚¸ãƒ£ãƒ³ãƒ«")]/following-sibling::td/text()').get().strip()
            item['address'] = article.xpath('.//table/tr/th[contains(text(), "ä½æ‰€")]/following-sibling::td/text()').get().strip()
            item['tel'] = article.xpath('.//table/tr/th[contains(text(), "é›»è©±ç•ªå·")]/following-sibling::td/text()').get().strip()
            item['offical_page'] = article.xpath('.//table/tr/th[contains(text(), "U R L")]/following-sibling::td/a/@href').get()

            self.logzero_logger.debug(item)
            yield item

        # ã€Œ>ã€ãƒœã‚¿ãƒ³ãŒãªã‘ã‚Œã°(æœ€çµ‚ãƒšãƒ¼ã‚¸ãªã®ã§)çµ‚äº†
        next_page = response.xpath('//div[@role="navigation"]/a[@rel="next"]/@href').extract_first()
        if next_page is None:
            self.logzero_logger.info('ğŸ’» finished. last page = ' + response.request.url)
            return

        self.logzero_logger.info(f'ğŸ›« next url = {next_page}')

        yield scrapy.Request(next_page, callback=self.parse)
