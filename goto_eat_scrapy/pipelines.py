# Define your item pipelines here
#
# Don't forget to add your pipeline to the ITEM_PIPELINES setting
# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html

import re

import scrapy
import w3lib
from itemadapter import ItemAdapter

from goto_eat_scrapy.items import ShopItem


def normalize_text(text):
    if not text:
        return text

    text = w3lib.html.remove_tags(text)
    text = "".join(text.splitlines())

    return text.strip()


class GotoEatScrapyPipeline:
    def process_item(self, item, spider):
        # æ­£è¦åŒ–(æ”¹è¡Œã‚³ãƒ¼ãƒ‰å‰Šé™¤ã€HTMLã‚¿ã‚°å‰Šé™¤ã€strip()ç­‰)
        item = self._normalize(item, spider)
        # ãƒ­ã‚°å‡ºåŠ›
        spider.logzero_logger.debug(item)
        return item

    def _normalize(self, item, spider):
        # æ”¹è¡Œã‚³ãƒ¼ãƒ‰å‰Šé™¤ã¨HTMLã‚¿ã‚°ã®å‰Šé™¤ã‚’è¡Œã†é …ç›®
        # MEMO: å²é˜œã€èŒ¨åŸã€ä¸‰é‡ã§ä½¿ã‚ã‚Œã¦ã„ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€official_page(URL)ä¸­ã«HTMLã‚¿ã‚°ãŒå«ã¾ã‚Œã‚‹ã®ãŒã„ãã¤ã‹ã‚ã‚‹
        for attr in ["shop_name", "address", "opening_hours", "closing_day"]:
            if (text := item.get(attr)) :
                item[attr] = normalize_text(text)

        # strip()ã™ã‚‹ã ã‘ã®é …ç›®
        for attr in ["genre_name", "area_name", "tel", "zip_code"]:
            if (text := item.get(attr)) :
                item[attr] = text.strip()

        return item

    def open_spider(self, spider):
        spider.logzero_logger.info(f"ğŸš€ [{spider.name}] start")

    def close_spider(self, spider):
        spider.logzero_logger.info(f"ğŸª‚ [{spider.name}]  end ")


if __name__ == "__main__":
    # usage:
    # $ python -m goto_eat_scrapy.pipelines

    res = normalize_text("å±±ä¸‹<br>ç”º12-12\r\n  ä¸€äºŒä¸‰ãƒ“ãƒ«1F")
    assert "å±±ä¸‹ç”º12-12  ä¸€äºŒä¸‰ãƒ“ãƒ«1F" == res, res

    print("success!!")
